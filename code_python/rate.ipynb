{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f40253",
   "metadata": {},
   "source": [
    "# 手写数字识别验证"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a28f5f",
   "metadata": {},
   "source": [
    "## 导入训练好的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4822ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d305f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = 0.1307\n",
    "STANDARD_DEVIATION = 0.3081\n",
    "class lenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dnn=torch.nn.Sequential(nn.Conv2d(1, 6, kernel_size=5,padding=2),\n",
    "                          nn.Sigmoid(),\n",
    "                          nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                          nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "                          nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
    "                          nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "                          nn.Linear(120, 84), nn.Sigmoid(), nn.Linear(84, 10))\n",
    "    def forward(self,x):\n",
    "        x = x.reshape(500, 500, 4)\n",
    "        x = torch.narrow(x, dim=2, start=0, length=1)\n",
    "        x = x.reshape(1, 1, 500, 500)\n",
    "        \n",
    "        x = F.max_pool2d(x, 14, stride=18)\n",
    "\n",
    "        out=self.dnn(x)\n",
    "        out= F.softmax(out, dim=1)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e34de8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('../data/number/11.png',0)\n",
    "for i in range(500):\n",
    "    for j in range(500):\n",
    "        img[i][j]=255-img[i][j]\n",
    "cv2.imwrite('../data/number/reverse11.png',img)\n",
    "img=img.reshape(1,1,500,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27da4405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85e5799c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47595bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=torch.from_numpy(img).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5463da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=F.avg_pool2d(img,14,stride=18)\n",
    "#m=torch.nn.AdaptiveMaxPool2d(28)\n",
    "#img=m(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69a37169",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98597c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=img.reshape(28,28)\n",
    "cv2.imwrite('../data/number/avgpool11.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "155db778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le=lenet()\n",
    "le.load_state_dict(torch.load('../model_save/netmax_try4onnx.pth'))\n",
    "# le=le.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d21a7e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lenet(\n",
       "  (dnn): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): Sigmoid()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): Sigmoid()\n",
       "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    (7): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (8): Sigmoid()\n",
       "    (9): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (10): Sigmoid()\n",
       "    (11): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.randn(500,500,4)\n",
    "le.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b4b29c75",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unsupported: ONNX export of operator adaptive_max_pool2d, since output size is not factor of input size. Please feel free to request support or submit a pull request on PyTorch GitHub.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-1574c41ac39b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m500\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'onnx_model_softmax500_bi_adpmaxpool.onnx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\software\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\__init__.py\u001b[0m in \u001b[0;36mexport\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[0;32m    318\u001b[0m                         \u001b[0m_retain_param_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_constant_folding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                         \u001b[0mstrip_doc_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                         custom_opsets, enable_onnx_checker, use_external_data_format)\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\utils.py\u001b[0m in \u001b[0;36mexport\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mdo_constant_folding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdo_constant_folding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexample_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mdynamic_axes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             custom_opsets=custom_opsets, use_external_data_format=use_external_data_format)\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\utils.py\u001b[0m in \u001b[0;36m_export\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, use_external_data_format, onnx_shape_inference)\u001b[0m\n\u001b[0;32m    727\u001b[0m                                 \u001b[0mfixed_batch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfixed_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m                                 \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m                                 dynamic_axes=dynamic_axes)\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m             \u001b[1;31m# TODO: Don't allocate a in-memory string for the protobuf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[1;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[0;32m    499\u001b[0m                             \u001b[0mfixed_batch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfixed_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m                             \u001b[0mdynamic_axes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m                             module=module)\n\u001b[0m\u001b[0;32m    502\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbolic_helper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_onnx_shape_inference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScriptModule\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScriptFunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\utils.py\u001b[0m in \u001b[0;36m_optimize_graph\u001b[1;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[0mdynamic_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdynamic_axes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_pass_onnx_set_dynamic_input_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_pass_onnx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_pass_lint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\__init__.py\u001b[0m in \u001b[0;36m_run_symbolic_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_run_symbolic_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_symbolic_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\utils.py\u001b[0m in \u001b[0;36m_run_symbolic_function\u001b[1;34m(g, block, n, inputs, env, operator_export_type)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m                 \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattributeNames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msymbolic_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mns\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"prim\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\symbolic_opset9.py\u001b[0m in \u001b[0;36msymbolic_fn\u001b[1;34m(g, input, output_size)\u001b[0m\n\u001b[0;32m    988\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_unimplemented\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output size that are not factor of input size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msym_help\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_onnx_unsupported\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\", since output size is not factor of input size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m         \u001b[1;31m# call max_poolxd_with_indices to get indices in the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\symbolic_helper.py\u001b[0m in \u001b[0;36m_onnx_unsupported\u001b[1;34m(op_name)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_onnx_unsupported\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     raise RuntimeError(\"Unsupported: ONNX export of operator {}. \"\n\u001b[1;32m--> 263\u001b[1;33m                        \"Please feel free to request support or submit a pull request on PyTorch GitHub.\".format(op_name))\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unsupported: ONNX export of operator adaptive_max_pool2d, since output size is not factor of input size. Please feel free to request support or submit a pull request on PyTorch GitHub."
     ]
    }
   ],
   "source": [
    "dummy_input = torch.zeros(500 * 500 * 4)\n",
    "torch.onnx.export(le, dummy_input, 'onnx_model_softmax500_bi_adpmaxpool.onnx', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ad0b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = [\"input\"]\n",
    "output_names = [\"output\"]\n",
    "batch_size = 1\n",
    "input_shape = (batch_size, 1, 28, 28)\n",
    "output_shape = (batch_size, 10)\n",
    " \n",
    "# 将 PyTorch 模型转换为 ONNX 格式\n",
    "torch.onnx.export(\n",
    "    le,  # 要转换的 PyTorch 模型\n",
    "    torch.randn(input_shape),  # 模型输入的随机张量\n",
    "    \"lenet2.onnx\",  # 保存的 ONNX 模型的文件名\n",
    "    input_names=input_names,  # 输入张量的名称\n",
    "    output_names=output_names,  # 输出张量的名称\n",
    "    dynamic_axes={input_names[0]: {0: \"batch_size\"}, output_names[0]: {0: \"batch_size\"}}  # 动态轴，即输入和输出张量可以具有不同的批次大小\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8bc9f8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch output: [[ 2.2400398  -2.1915765   2.9717813  -1.7777514  -6.782894    0.37631506\n",
      "  -0.42980683 -2.684063   -2.1112046  -6.4059377 ]]\n",
      "ONNX output: [[ 2.2400405  -2.1915767   2.9717815  -1.777752   -6.7828927   0.37631458\n",
      "  -0.42980716 -2.684062   -2.1112056  -6.4059377 ]]\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(\"lenet2.onnx\")\n",
    "onnx_model_graph = onnx_model.graph\n",
    "onnx_session = onnxruntime.InferenceSession(onnx_model.SerializeToString())\n",
    " \n",
    "# 使用随机张量测试 ONNX 模型\n",
    "x = torch.randn((1,1,28,28)).numpy()\n",
    "onnx_output = onnx_session.run(output_names, {input_names[0]: x})[0]\n",
    " \n",
    "print(f\"PyTorch output: {le(torch.from_numpy(x)).detach().numpy()}\")\n",
    "print(f\"ONNX output: {onnx_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5901490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(le,dummy_input.to(device),'../model_save/lenet.onnx',export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eb6bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0041a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "onnx_model=onnx.load(\"../model_save/lenet.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e07c7aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run(): incompatible function arguments. The following argument types are supported:\n    1. (self: onnxruntime.capi.onnxruntime_pybind11_state.InferenceSession, arg0: List[str], arg1: Dict[str, object], arg2: onnxruntime.capi.onnxruntime_pybind11_state.RunOptions) -> List[object]\n\nInvoked with: <onnxruntime.capi.onnxruntime_pybind11_state.InferenceSession object at 0x0000027670CA3AE8>, 'input', tensor([[[[-4.0397e-01, -1.3191e+00, -1.0654e+00,  2.4199e-01,  3.3594e-01,\n           -6.6109e-01, -2.0142e+00,  1.6725e+00, -6.4353e-01, -1.0101e+00,\n           -9.2619e-01, -1.1033e+00, -1.9078e+00, -7.1602e-01, -7.4355e-01,\n            6.4440e-01,  1.1813e-01, -5.4673e-01,  7.7746e-01, -1.9279e+00,\n            4.1781e-01,  2.8851e-01,  1.9069e+00, -1.3366e+00, -1.5414e+00,\n           -4.2140e-01,  2.2912e-01,  4.2076e-01],\n          [-9.1246e-02,  2.0045e+00, -4.1086e-01,  4.2875e-01, -1.0772e+00,\n           -8.6018e-01, -9.7969e-01,  1.4211e+00, -3.2899e-01, -1.7097e+00,\n           -8.6773e-02,  1.2771e+00,  1.5335e-01,  1.3973e+00,  9.5377e-01,\n           -1.6732e+00, -2.5205e-01, -1.7308e-01,  1.1654e+00, -9.0109e-02,\n            9.9234e-01, -6.0061e-01,  6.9673e-01,  7.9512e-02,  7.0338e-01,\n            5.4901e-01, -1.2978e+00,  5.7065e-01],\n          [-2.1937e-01, -2.5879e-01, -2.0446e+00,  1.5693e+00,  9.4459e-02,\n            7.0863e-01, -2.4875e-03, -5.7800e-01,  7.7063e-01, -3.1354e-01,\n           -2.4186e+00, -1.1656e+00, -2.5346e+00, -2.9595e-01, -8.5713e-01,\n            1.2693e+00, -1.4876e-01, -1.1486e+00,  1.5861e-01, -2.9359e-01,\n            2.9034e-01, -6.3678e-01, -6.9839e-01,  5.4364e-02, -2.8492e-01,\n            4.9896e-01, -1.2237e-02, -6.6402e-01],\n          [-1.2370e+00,  6.0340e-01,  1.1778e-02, -1.9156e+00,  1.6093e+00,\n           -8.0026e-01,  1.6868e+00,  1.1492e+00,  1.5530e+00,  1.4407e+00,\n            1.1777e+00,  1.4641e+00, -4.2737e-01, -7.5301e-01, -2.0487e+00,\n            1.5927e+00, -1.5626e-01,  1.0487e+00,  5.6664e-01,  1.8411e+00,\n            1.6131e+00, -8.7063e-01,  4.6826e-01, -4.2799e-01,  1.8120e-01,\n           -9.6187e-02, -2.4744e-01,  5.5140e-01],\n          [ 8.5801e-02,  1.1383e+00, -1.3296e+00,  1.4276e+00,  2.9799e-03,\n            3.6227e-01, -4.3414e-01, -1.4669e+00,  1.6089e+00,  1.0099e+00,\n           -1.2694e+00, -4.2748e-01, -1.1609e+00, -2.7290e-01,  4.2598e-01,\n            7.0670e-01,  2.0931e-02, -9.1848e-02,  5.0056e-01, -6.0049e-01,\n           -4.9919e-01,  1.9432e-01,  9.2865e-01, -4.0791e-01,  3.4366e-01,\n            1.1718e+00,  2.1782e-01,  3.6987e-01],\n          [-1.3027e-02,  9.8231e-01,  6.6163e-01,  8.4952e-01,  1.3937e+00,\n            2.3442e-01, -3.7117e-01, -6.9666e-01,  5.4456e-01, -9.5748e-01,\n           -7.6729e-01, -4.7614e-02,  6.7197e-01,  5.0354e-01,  9.0730e-01,\n            1.0937e+00, -1.8147e-01, -1.2941e+00,  1.1720e+00,  3.6451e-01,\n            6.3728e-01,  1.0549e+00, -1.3608e+00,  3.4166e-01,  7.2265e-01,\n           -6.7634e-01, -2.4423e-01, -1.3748e+00],\n          [ 1.7984e+00,  1.8761e-01,  1.3590e+00, -1.6628e+00,  9.1681e-02,\n            1.2122e+00, -1.4412e+00, -1.4845e+00,  1.8669e+00, -3.7083e-01,\n           -1.3061e-02,  4.3844e-01, -8.2647e-01, -4.5615e-01, -1.7015e+00,\n           -1.6780e+00, -4.0134e-01,  8.6633e-01, -1.4777e+00, -1.0646e+00,\n            4.2370e-01,  1.8278e+00,  7.5025e-01, -2.1848e+00,  4.2424e-01,\n           -8.7667e-02, -4.8564e-01, -7.6409e-02],\n          [-9.9521e-01,  9.3653e-01,  1.9649e+00, -7.2424e-01, -1.7260e+00,\n            7.2775e-03, -9.2508e-01,  2.2325e+00,  3.9088e-01, -2.0533e-01,\n            4.2781e-01,  1.5713e+00,  2.4062e-01,  1.6549e+00, -6.8804e-01,\n            4.7774e-01,  6.7255e-01, -1.8602e+00, -8.0015e-01,  3.0612e-01,\n           -4.8778e-01,  1.2691e+00,  3.2081e-01, -4.2424e-01,  1.7301e+00,\n            9.0053e-01,  3.5465e-02, -2.3517e-01],\n          [ 4.8151e-01,  1.9534e+00, -5.4456e-01, -2.2085e+00,  1.1024e+00,\n           -1.5576e+00, -9.6314e-01,  2.0214e+00,  4.2861e-01,  1.4267e+00,\n            3.7868e-02,  5.4827e-01,  1.9331e+00,  1.8097e+00,  9.2860e-01,\n            2.9418e-01,  2.0450e+00,  1.2581e+00, -1.8159e+00,  2.4931e+00,\n           -1.8643e+00,  6.4564e-01,  2.3840e-01, -4.3896e-01, -1.2792e+00,\n           -2.7006e-01,  6.6960e-01,  3.4275e+00],\n          [-6.2260e-01, -7.2953e-01, -3.1082e-01,  1.0151e+00,  1.1478e+00,\n           -5.0965e-01,  1.1835e+00, -1.6112e-01, -1.9160e+00,  3.5198e-01,\n            1.0146e+00,  4.4166e-01, -3.1504e-01, -3.6408e-01,  6.7421e-01,\n           -1.0409e+00,  1.1725e+00,  5.1629e-02,  2.8473e-01,  9.2540e-01,\n           -1.2104e+00,  1.1135e-01, -1.1585e+00, -2.3254e-01,  6.9775e-01,\n            6.6586e-01, -3.8892e-01, -1.8399e-01],\n          [-8.0357e-01, -1.4854e-01, -6.5233e-01,  5.5514e-01, -9.5979e-01,\n            1.1534e+00,  8.5120e-03, -1.5021e+00, -1.4416e+00,  4.4126e-01,\n            5.5441e-01, -1.5147e+00, -2.8391e-01,  1.3504e+00, -5.8148e-01,\n            4.0760e-01, -7.8970e-01,  8.2851e-01, -1.1551e+00,  1.4992e-01,\n            1.1605e-01, -4.4122e-01,  1.1451e-01,  1.5144e-01,  4.2363e-01,\n           -1.4434e+00, -1.0629e+00, -1.1443e+00],\n          [-5.1412e-01,  5.7820e-01,  7.9681e-01, -5.5964e-01,  1.8050e+00,\n           -5.0108e-01,  4.6224e-01, -7.5932e-01, -8.4260e-01,  7.6337e-03,\n            5.8610e-01,  8.8889e-01, -4.5770e-01, -1.9450e-01,  5.9243e-01,\n           -2.7511e-01, -9.7636e-01,  7.7287e-01,  1.0451e+00, -1.0411e+00,\n           -1.0893e+00,  8.0216e-01,  1.1301e+00,  1.9242e-01, -2.5377e+00,\n           -6.1255e-01,  4.9291e-01, -4.1430e-01],\n          [ 3.0340e-01, -1.3215e-02, -8.7678e-01, -6.5703e-01, -1.0473e-02,\n            6.8024e-01,  1.7638e+00, -2.2953e-01, -3.2996e-01, -2.3265e+00,\n           -9.7428e-01, -1.7145e+00,  9.0744e-01,  1.2059e+00, -4.9916e-01,\n            2.0861e-01,  1.1608e+00,  1.0101e-01,  5.4818e-01, -1.0277e+00,\n           -2.3299e+00,  3.7956e-01, -6.9055e-01,  6.7483e-01, -2.2522e-01,\n           -1.3572e+00,  3.5956e-01, -3.5338e-01],\n          [ 3.7039e-01,  1.0436e+00, -6.6591e-01,  4.4292e-01, -1.8024e-01,\n           -1.8204e+00,  8.1449e-01,  1.2938e+00, -1.0311e-01,  1.0394e+00,\n            2.7133e-01, -1.4117e-02, -1.6930e-01, -1.2000e+00,  1.1267e+00,\n           -1.1516e+00, -9.1875e-01,  3.6204e-01,  1.3606e+00,  2.5732e+00,\n            1.5314e+00, -3.5262e-01, -9.9679e-01, -6.2457e-02, -6.6554e-01,\n           -1.3528e+00,  8.9845e-01,  1.1784e+00],\n          [ 8.6255e-01, -3.1864e-01,  1.1794e+00, -1.7319e-01,  6.0270e-03,\n            6.7886e-01,  5.5353e-01, -1.3724e+00, -2.2888e+00,  2.3289e-01,\n           -2.6065e-01,  7.1020e-01, -2.0795e+00,  3.0346e-01,  3.2451e-01,\n           -9.8856e-01, -4.8228e-01,  6.2455e-01, -4.5910e-01, -5.6137e-01,\n            1.7452e-01,  3.9466e-01, -6.6225e-01,  8.2220e-02, -1.1126e+00,\n            1.7059e-01, -1.3233e+00, -1.3008e+00],\n          [-7.8186e-01,  1.4488e+00,  7.5118e-01, -1.7471e+00,  2.7726e-01,\n            2.1034e+00, -8.8990e-01,  1.1850e-01,  2.9937e-01,  6.5412e-01,\n            3.6724e-01,  1.2067e-01, -1.0756e+00, -9.9272e-01,  2.2657e+00,\n           -3.6644e-01, -1.3722e-01,  5.7101e-01,  1.3797e-01, -1.9952e+00,\n           -1.0396e+00,  4.7417e-01,  7.0138e-01,  1.4039e-01, -3.9140e-01,\n           -5.8435e-01, -3.0427e-01,  1.1052e+00],\n          [-2.0791e-01,  6.2571e-01, -3.8418e-01, -1.0551e+00, -2.0745e+00,\n            5.5539e-01,  1.8344e-01,  1.1320e+00, -1.4594e+00,  1.6664e-01,\n           -1.2903e+00, -1.2352e+00,  1.1591e+00, -1.5790e-01,  8.8099e-02,\n           -4.5291e-01,  7.1242e-01,  1.3689e+00, -8.8870e-01, -1.4943e-01,\n           -3.6666e-01,  3.9863e-01,  2.2160e-01,  3.8335e-01, -7.8326e-01,\n           -1.9040e-01, -1.1653e+00,  7.8067e-01],\n          [-3.5953e-01, -1.8270e+00,  1.2217e+00,  5.3934e-01,  2.5517e-01,\n            4.9151e-01, -5.1759e-01,  2.8093e-01,  5.0212e-01,  7.0557e-02,\n           -8.2857e-01, -8.6795e-01, -5.3515e-01, -7.0367e-01, -4.9753e-01,\n           -7.3815e-01, -7.9974e-01, -1.8884e-01, -1.0567e-01, -1.1153e-01,\n            8.8477e-01,  1.0176e+00,  1.3445e+00, -1.0749e+00,  2.9421e-01,\n           -6.0429e-01, -7.7857e-01, -2.1369e-01],\n          [ 1.3160e+00,  5.3721e-02, -1.0446e+00, -3.5275e-01, -7.1920e-02,\n            2.9507e-02,  9.1292e-01, -4.1606e-01,  1.3895e+00, -1.4769e+00,\n            8.5820e-01,  2.2351e-01, -1.0277e-01,  9.7807e-01,  3.5723e-01,\n           -4.3778e-02, -1.4351e-01, -1.8396e-03, -1.0030e+00,  6.0808e-01,\n           -8.5951e-01, -1.3644e+00,  1.9288e+00, -1.8176e-01,  4.7795e-01,\n            4.2933e-01,  1.9349e-01, -1.9983e-01],\n          [-7.8097e-01,  1.1128e+00,  1.4291e+00,  3.5639e-01,  1.0197e+00,\n           -9.8546e-01,  9.9550e-01,  5.5338e-01, -1.4533e+00, -3.4172e-01,\n           -2.5023e-01, -7.9325e-01, -1.5309e+00, -5.5901e-01,  9.5208e-01,\n           -2.0396e+00, -6.8245e-01,  9.3847e-01,  3.4836e-01,  2.7518e-01,\n           -1.7210e+00,  4.2314e-01,  3.4635e-01,  4.4251e-01,  5.2385e-01,\n            2.1591e+00,  9.8429e-01,  8.6303e-01],\n          [ 1.6815e-01, -2.7772e-02, -1.0734e+00, -4.6910e-02, -8.4630e-02,\n            2.1705e+00,  6.5751e-01, -7.0239e-01,  9.4747e-01, -6.1022e-02,\n            6.7870e-01, -1.6114e+00, -5.3897e-01, -5.0953e-01,  7.7722e-01,\n           -1.1879e+00,  2.5445e-01, -1.1869e+00,  6.9696e-01, -4.9559e-01,\n           -1.5233e+00,  8.9675e-01, -1.1001e+00, -3.0110e-01, -7.7018e-01,\n            4.3091e-01,  1.2922e+00,  2.0981e+00],\n          [ 3.7264e-02,  1.2153e+00, -9.3959e-02,  4.0807e-01, -7.9238e-01,\n            1.0585e+00,  1.0105e+00,  1.7173e-01, -6.6411e-01,  1.0819e+00,\n           -8.7215e-02,  3.9109e-01, -3.2822e-01, -2.2076e+00, -1.3531e+00,\n           -2.9919e-01, -1.0197e+00, -7.3336e-02, -1.0536e+00, -1.6434e+00,\n            2.0954e+00, -4.6359e-01, -1.2364e+00,  1.0624e-01, -1.9646e+00,\n            1.6943e+00,  1.1102e+00, -3.4004e-01],\n          [-1.1547e+00, -3.0847e-01,  1.1148e-03,  9.3540e-02, -3.0517e+00,\n            1.1328e-02, -2.9225e-01,  2.7704e-01,  6.6628e-01,  9.9592e-01,\n            4.0138e-01, -3.4158e-01, -9.0343e-01, -8.8401e-01, -1.7744e-01,\n           -6.9720e-01,  8.7558e-01,  2.0803e-01,  7.8448e-01, -8.1962e-02,\n            1.2626e+00,  1.1143e+00,  8.2311e-01,  4.1416e-01, -4.8515e-01,\n           -1.6372e+00, -1.3235e+00, -1.5880e+00],\n          [-1.3774e+00, -2.0500e+00,  1.0666e+00, -1.9228e+00, -7.1990e-01,\n           -1.3182e+00, -1.0816e+00,  6.2433e-01,  6.5890e-01,  1.9460e+00,\n            7.1916e-01, -1.1283e+00,  6.6809e-01,  1.3113e+00,  1.0861e+00,\n           -1.9819e-01, -1.0193e-02,  7.1959e-01, -9.0179e-01,  6.0905e-01,\n            8.7121e-01, -5.0338e-01,  4.1490e-01,  6.4838e-01,  9.9912e-02,\n            1.1808e-01, -9.2869e-01, -4.7884e-01],\n          [ 1.5949e-01, -1.5003e+00,  4.0569e-01,  1.2431e+00,  3.7463e-01,\n            4.5221e-01, -9.0351e-01, -1.2663e+00, -8.6103e-01, -7.1476e-01,\n           -1.4146e+00,  5.5666e-02, -1.0520e+00,  1.2061e+00, -9.6190e-02,\n            1.5356e-01, -5.6167e-01, -1.1372e+00, -7.7529e-01, -1.4873e+00,\n           -3.1879e-01, -4.4630e-01,  4.9759e-01, -3.7340e-02, -3.4783e+00,\n           -5.2820e-01, -3.4294e-01, -4.0964e-01],\n          [ 6.4749e-01, -8.9358e-01, -1.8980e+00,  6.2574e-01, -2.5811e-01,\n            1.4880e+00,  1.0682e-01, -1.4787e-01, -1.5963e+00, -1.4048e+00,\n           -6.5746e-02, -3.1647e-01, -7.9017e-01,  1.5572e+00, -6.7455e-01,\n           -2.6214e-01, -1.7161e-01,  8.3393e-01, -9.5916e-01, -1.8439e-01,\n           -6.5539e-01,  5.1099e-01, -3.9781e-01,  6.0908e-01, -2.1161e-02,\n           -4.1636e-01, -1.2912e+00,  9.5027e-01],\n          [ 1.6386e+00,  9.1130e-01, -2.9084e-02,  8.8033e-01,  1.3543e+00,\n           -1.4643e+00, -2.5046e-02,  6.2117e-01,  1.0609e+00,  6.6845e-01,\n            1.5821e-01, -1.0598e+00, -3.3876e+00, -1.1218e+00, -1.4019e+00,\n            2.4498e+00, -7.1469e-01, -1.2732e+00, -1.6108e-01, -1.8009e-01,\n           -4.4487e-01,  4.8994e-01, -7.7627e-01, -1.9196e+00,  1.4769e+00,\n           -5.7532e-01,  1.4515e-01,  2.4947e-01],\n          [-9.3452e-01, -1.4012e+00, -6.3710e-01, -1.1447e+00,  7.1016e-01,\n            1.5342e+00,  1.4210e+00,  2.0957e+00,  5.6102e-01,  2.5351e-01,\n           -6.1829e-01, -9.8880e-01,  6.0835e-01, -1.6596e-01, -2.4013e-01,\n           -2.3057e-01, -1.0792e+00,  4.8203e-01, -4.2513e-01, -1.1715e+00,\n            5.4854e-01,  7.9151e-01,  6.4677e-01,  9.7515e-01,  4.1157e-01,\n            7.2924e-01,  6.7465e-02, -1.3425e+00]]]]), None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-29a8c9255de7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# 运行ONNX模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mort_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# 获取输出信息\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda\\envs\\pytorch\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: run(): incompatible function arguments. The following argument types are supported:\n    1. (self: onnxruntime.capi.onnxruntime_pybind11_state.InferenceSession, arg0: List[str], arg1: Dict[str, object], arg2: onnxruntime.capi.onnxruntime_pybind11_state.RunOptions) -> List[object]\n\nInvoked with: <onnxruntime.capi.onnxruntime_pybind11_state.InferenceSession object at 0x0000027670CA3AE8>, 'input', tensor([[[[-4.0397e-01, -1.3191e+00, -1.0654e+00,  2.4199e-01,  3.3594e-01,\n           -6.6109e-01, -2.0142e+00,  1.6725e+00, -6.4353e-01, -1.0101e+00,\n           -9.2619e-01, -1.1033e+00, -1.9078e+00, -7.1602e-01, -7.4355e-01,\n            6.4440e-01,  1.1813e-01, -5.4673e-01,  7.7746e-01, -1.9279e+00,\n            4.1781e-01,  2.8851e-01,  1.9069e+00, -1.3366e+00, -1.5414e+00,\n           -4.2140e-01,  2.2912e-01,  4.2076e-01],\n          [-9.1246e-02,  2.0045e+00, -4.1086e-01,  4.2875e-01, -1.0772e+00,\n           -8.6018e-01, -9.7969e-01,  1.4211e+00, -3.2899e-01, -1.7097e+00,\n           -8.6773e-02,  1.2771e+00,  1.5335e-01,  1.3973e+00,  9.5377e-01,\n           -1.6732e+00, -2.5205e-01, -1.7308e-01,  1.1654e+00, -9.0109e-02,\n            9.9234e-01, -6.0061e-01,  6.9673e-01,  7.9512e-02,  7.0338e-01,\n            5.4901e-01, -1.2978e+00,  5.7065e-01],\n          [-2.1937e-01, -2.5879e-01, -2.0446e+00,  1.5693e+00,  9.4459e-02,\n            7.0863e-01, -2.4875e-03, -5.7800e-01,  7.7063e-01, -3.1354e-01,\n           -2.4186e+00, -1.1656e+00, -2.5346e+00, -2.9595e-01, -8.5713e-01,\n            1.2693e+00, -1.4876e-01, -1.1486e+00,  1.5861e-01, -2.9359e-01,\n            2.9034e-01, -6.3678e-01, -6.9839e-01,  5.4364e-02, -2.8492e-01,\n            4.9896e-01, -1.2237e-02, -6.6402e-01],\n          [-1.2370e+00,  6.0340e-01,  1.1778e-02, -1.9156e+00,  1.6093e+00,\n           -8.0026e-01,  1.6868e+00,  1.1492e+00,  1.5530e+00,  1.4407e+00,\n            1.1777e+00,  1.4641e+00, -4.2737e-01, -7.5301e-01, -2.0487e+00,\n            1.5927e+00, -1.5626e-01,  1.0487e+00,  5.6664e-01,  1.8411e+00,\n            1.6131e+00, -8.7063e-01,  4.6826e-01, -4.2799e-01,  1.8120e-01,\n           -9.6187e-02, -2.4744e-01,  5.5140e-01],\n          [ 8.5801e-02,  1.1383e+00, -1.3296e+00,  1.4276e+00,  2.9799e-03,\n            3.6227e-01, -4.3414e-01, -1.4669e+00,  1.6089e+00,  1.0099e+00,\n           -1.2694e+00, -4.2748e-01, -1.1609e+00, -2.7290e-01,  4.2598e-01,\n            7.0670e-01,  2.0931e-02, -9.1848e-02,  5.0056e-01, -6.0049e-01,\n           -4.9919e-01,  1.9432e-01,  9.2865e-01, -4.0791e-01,  3.4366e-01,\n            1.1718e+00,  2.1782e-01,  3.6987e-01],\n          [-1.3027e-02,  9.8231e-01,  6.6163e-01,  8.4952e-01,  1.3937e+00,\n            2.3442e-01, -3.7117e-01, -6.9666e-01,  5.4456e-01, -9.5748e-01,\n           -7.6729e-01, -4.7614e-02,  6.7197e-01,  5.0354e-01,  9.0730e-01,\n            1.0937e+00, -1.8147e-01, -1.2941e+00,  1.1720e+00,  3.6451e-01,\n            6.3728e-01,  1.0549e+00, -1.3608e+00,  3.4166e-01,  7.2265e-01,\n           -6.7634e-01, -2.4423e-01, -1.3748e+00],\n          [ 1.7984e+00,  1.8761e-01,  1.3590e+00, -1.6628e+00,  9.1681e-02,\n            1.2122e+00, -1.4412e+00, -1.4845e+00,  1.8669e+00, -3.7083e-01,\n           -1.3061e-02,  4.3844e-01, -8.2647e-01, -4.5615e-01, -1.7015e+00,\n           -1.6780e+00, -4.0134e-01,  8.6633e-01, -1.4777e+00, -1.0646e+00,\n            4.2370e-01,  1.8278e+00,  7.5025e-01, -2.1848e+00,  4.2424e-01,\n           -8.7667e-02, -4.8564e-01, -7.6409e-02],\n          [-9.9521e-01,  9.3653e-01,  1.9649e+00, -7.2424e-01, -1.7260e+00,\n            7.2775e-03, -9.2508e-01,  2.2325e+00,  3.9088e-01, -2.0533e-01,\n            4.2781e-01,  1.5713e+00,  2.4062e-01,  1.6549e+00, -6.8804e-01,\n            4.7774e-01,  6.7255e-01, -1.8602e+00, -8.0015e-01,  3.0612e-01,\n           -4.8778e-01,  1.2691e+00,  3.2081e-01, -4.2424e-01,  1.7301e+00,\n            9.0053e-01,  3.5465e-02, -2.3517e-01],\n          [ 4.8151e-01,  1.9534e+00, -5.4456e-01, -2.2085e+00,  1.1024e+00,\n           -1.5576e+00, -9.6314e-01,  2.0214e+00,  4.2861e-01,  1.4267e+00,\n            3.7868e-02,  5.4827e-01,  1.9331e+00,  1.8097e+00,  9.2860e-01,\n            2.9418e-01,  2.0450e+00,  1.2581e+00, -1.8159e+00,  2.4931e+00,\n           -1.8643e+00,  6.4564e-01,  2.3840e-01, -4.3896e-01, -1.2792e+00,\n           -2.7006e-01,  6.6960e-01,  3.4275e+00],\n          [-6.2260e-01, -7.2953e-01, -3.1082e-01,  1.0151e+00,  1.1478e+00,\n           -5.0965e-01,  1.1835e+00, -1.6112e-01, -1.9160e+00,  3.5198e-01,\n            1.0146e+00,  4.4166e-01, -3.1504e-01, -3.6408e-01,  6.7421e-01,\n           -1.0409e+00,  1.1725e+00,  5.1629e-02,  2.8473e-01,  9.2540e-01,\n           -1.2104e+00,  1.1135e-01, -1.1585e+00, -2.3254e-01,  6.9775e-01,\n            6.6586e-01, -3.8892e-01, -1.8399e-01],\n          [-8.0357e-01, -1.4854e-01, -6.5233e-01,  5.5514e-01, -9.5979e-01,\n            1.1534e+00,  8.5120e-03, -1.5021e+00, -1.4416e+00,  4.4126e-01,\n            5.5441e-01, -1.5147e+00, -2.8391e-01,  1.3504e+00, -5.8148e-01,\n            4.0760e-01, -7.8970e-01,  8.2851e-01, -1.1551e+00,  1.4992e-01,\n            1.1605e-01, -4.4122e-01,  1.1451e-01,  1.5144e-01,  4.2363e-01,\n           -1.4434e+00, -1.0629e+00, -1.1443e+00],\n          [-5.1412e-01,  5.7820e-01,  7.9681e-01, -5.5964e-01,  1.8050e+00,\n           -5.0108e-01,  4.6224e-01, -7.5932e-01, -8.4260e-01,  7.6337e-03,\n            5.8610e-01,  8.8889e-01, -4.5770e-01, -1.9450e-01,  5.9243e-01,\n           -2.7511e-01, -9.7636e-01,  7.7287e-01,  1.0451e+00, -1.0411e+00,\n           -1.0893e+00,  8.0216e-01,  1.1301e+00,  1.9242e-01, -2.5377e+00,\n           -6.1255e-01,  4.9291e-01, -4.1430e-01],\n          [ 3.0340e-01, -1.3215e-02, -8.7678e-01, -6.5703e-01, -1.0473e-02,\n            6.8024e-01,  1.7638e+00, -2.2953e-01, -3.2996e-01, -2.3265e+00,\n           -9.7428e-01, -1.7145e+00,  9.0744e-01,  1.2059e+00, -4.9916e-01,\n            2.0861e-01,  1.1608e+00,  1.0101e-01,  5.4818e-01, -1.0277e+00,\n           -2.3299e+00,  3.7956e-01, -6.9055e-01,  6.7483e-01, -2.2522e-01,\n           -1.3572e+00,  3.5956e-01, -3.5338e-01],\n          [ 3.7039e-01,  1.0436e+00, -6.6591e-01,  4.4292e-01, -1.8024e-01,\n           -1.8204e+00,  8.1449e-01,  1.2938e+00, -1.0311e-01,  1.0394e+00,\n            2.7133e-01, -1.4117e-02, -1.6930e-01, -1.2000e+00,  1.1267e+00,\n           -1.1516e+00, -9.1875e-01,  3.6204e-01,  1.3606e+00,  2.5732e+00,\n            1.5314e+00, -3.5262e-01, -9.9679e-01, -6.2457e-02, -6.6554e-01,\n           -1.3528e+00,  8.9845e-01,  1.1784e+00],\n          [ 8.6255e-01, -3.1864e-01,  1.1794e+00, -1.7319e-01,  6.0270e-03,\n            6.7886e-01,  5.5353e-01, -1.3724e+00, -2.2888e+00,  2.3289e-01,\n           -2.6065e-01,  7.1020e-01, -2.0795e+00,  3.0346e-01,  3.2451e-01,\n           -9.8856e-01, -4.8228e-01,  6.2455e-01, -4.5910e-01, -5.6137e-01,\n            1.7452e-01,  3.9466e-01, -6.6225e-01,  8.2220e-02, -1.1126e+00,\n            1.7059e-01, -1.3233e+00, -1.3008e+00],\n          [-7.8186e-01,  1.4488e+00,  7.5118e-01, -1.7471e+00,  2.7726e-01,\n            2.1034e+00, -8.8990e-01,  1.1850e-01,  2.9937e-01,  6.5412e-01,\n            3.6724e-01,  1.2067e-01, -1.0756e+00, -9.9272e-01,  2.2657e+00,\n           -3.6644e-01, -1.3722e-01,  5.7101e-01,  1.3797e-01, -1.9952e+00,\n           -1.0396e+00,  4.7417e-01,  7.0138e-01,  1.4039e-01, -3.9140e-01,\n           -5.8435e-01, -3.0427e-01,  1.1052e+00],\n          [-2.0791e-01,  6.2571e-01, -3.8418e-01, -1.0551e+00, -2.0745e+00,\n            5.5539e-01,  1.8344e-01,  1.1320e+00, -1.4594e+00,  1.6664e-01,\n           -1.2903e+00, -1.2352e+00,  1.1591e+00, -1.5790e-01,  8.8099e-02,\n           -4.5291e-01,  7.1242e-01,  1.3689e+00, -8.8870e-01, -1.4943e-01,\n           -3.6666e-01,  3.9863e-01,  2.2160e-01,  3.8335e-01, -7.8326e-01,\n           -1.9040e-01, -1.1653e+00,  7.8067e-01],\n          [-3.5953e-01, -1.8270e+00,  1.2217e+00,  5.3934e-01,  2.5517e-01,\n            4.9151e-01, -5.1759e-01,  2.8093e-01,  5.0212e-01,  7.0557e-02,\n           -8.2857e-01, -8.6795e-01, -5.3515e-01, -7.0367e-01, -4.9753e-01,\n           -7.3815e-01, -7.9974e-01, -1.8884e-01, -1.0567e-01, -1.1153e-01,\n            8.8477e-01,  1.0176e+00,  1.3445e+00, -1.0749e+00,  2.9421e-01,\n           -6.0429e-01, -7.7857e-01, -2.1369e-01],\n          [ 1.3160e+00,  5.3721e-02, -1.0446e+00, -3.5275e-01, -7.1920e-02,\n            2.9507e-02,  9.1292e-01, -4.1606e-01,  1.3895e+00, -1.4769e+00,\n            8.5820e-01,  2.2351e-01, -1.0277e-01,  9.7807e-01,  3.5723e-01,\n           -4.3778e-02, -1.4351e-01, -1.8396e-03, -1.0030e+00,  6.0808e-01,\n           -8.5951e-01, -1.3644e+00,  1.9288e+00, -1.8176e-01,  4.7795e-01,\n            4.2933e-01,  1.9349e-01, -1.9983e-01],\n          [-7.8097e-01,  1.1128e+00,  1.4291e+00,  3.5639e-01,  1.0197e+00,\n           -9.8546e-01,  9.9550e-01,  5.5338e-01, -1.4533e+00, -3.4172e-01,\n           -2.5023e-01, -7.9325e-01, -1.5309e+00, -5.5901e-01,  9.5208e-01,\n           -2.0396e+00, -6.8245e-01,  9.3847e-01,  3.4836e-01,  2.7518e-01,\n           -1.7210e+00,  4.2314e-01,  3.4635e-01,  4.4251e-01,  5.2385e-01,\n            2.1591e+00,  9.8429e-01,  8.6303e-01],\n          [ 1.6815e-01, -2.7772e-02, -1.0734e+00, -4.6910e-02, -8.4630e-02,\n            2.1705e+00,  6.5751e-01, -7.0239e-01,  9.4747e-01, -6.1022e-02,\n            6.7870e-01, -1.6114e+00, -5.3897e-01, -5.0953e-01,  7.7722e-01,\n           -1.1879e+00,  2.5445e-01, -1.1869e+00,  6.9696e-01, -4.9559e-01,\n           -1.5233e+00,  8.9675e-01, -1.1001e+00, -3.0110e-01, -7.7018e-01,\n            4.3091e-01,  1.2922e+00,  2.0981e+00],\n          [ 3.7264e-02,  1.2153e+00, -9.3959e-02,  4.0807e-01, -7.9238e-01,\n            1.0585e+00,  1.0105e+00,  1.7173e-01, -6.6411e-01,  1.0819e+00,\n           -8.7215e-02,  3.9109e-01, -3.2822e-01, -2.2076e+00, -1.3531e+00,\n           -2.9919e-01, -1.0197e+00, -7.3336e-02, -1.0536e+00, -1.6434e+00,\n            2.0954e+00, -4.6359e-01, -1.2364e+00,  1.0624e-01, -1.9646e+00,\n            1.6943e+00,  1.1102e+00, -3.4004e-01],\n          [-1.1547e+00, -3.0847e-01,  1.1148e-03,  9.3540e-02, -3.0517e+00,\n            1.1328e-02, -2.9225e-01,  2.7704e-01,  6.6628e-01,  9.9592e-01,\n            4.0138e-01, -3.4158e-01, -9.0343e-01, -8.8401e-01, -1.7744e-01,\n           -6.9720e-01,  8.7558e-01,  2.0803e-01,  7.8448e-01, -8.1962e-02,\n            1.2626e+00,  1.1143e+00,  8.2311e-01,  4.1416e-01, -4.8515e-01,\n           -1.6372e+00, -1.3235e+00, -1.5880e+00],\n          [-1.3774e+00, -2.0500e+00,  1.0666e+00, -1.9228e+00, -7.1990e-01,\n           -1.3182e+00, -1.0816e+00,  6.2433e-01,  6.5890e-01,  1.9460e+00,\n            7.1916e-01, -1.1283e+00,  6.6809e-01,  1.3113e+00,  1.0861e+00,\n           -1.9819e-01, -1.0193e-02,  7.1959e-01, -9.0179e-01,  6.0905e-01,\n            8.7121e-01, -5.0338e-01,  4.1490e-01,  6.4838e-01,  9.9912e-02,\n            1.1808e-01, -9.2869e-01, -4.7884e-01],\n          [ 1.5949e-01, -1.5003e+00,  4.0569e-01,  1.2431e+00,  3.7463e-01,\n            4.5221e-01, -9.0351e-01, -1.2663e+00, -8.6103e-01, -7.1476e-01,\n           -1.4146e+00,  5.5666e-02, -1.0520e+00,  1.2061e+00, -9.6190e-02,\n            1.5356e-01, -5.6167e-01, -1.1372e+00, -7.7529e-01, -1.4873e+00,\n           -3.1879e-01, -4.4630e-01,  4.9759e-01, -3.7340e-02, -3.4783e+00,\n           -5.2820e-01, -3.4294e-01, -4.0964e-01],\n          [ 6.4749e-01, -8.9358e-01, -1.8980e+00,  6.2574e-01, -2.5811e-01,\n            1.4880e+00,  1.0682e-01, -1.4787e-01, -1.5963e+00, -1.4048e+00,\n           -6.5746e-02, -3.1647e-01, -7.9017e-01,  1.5572e+00, -6.7455e-01,\n           -2.6214e-01, -1.7161e-01,  8.3393e-01, -9.5916e-01, -1.8439e-01,\n           -6.5539e-01,  5.1099e-01, -3.9781e-01,  6.0908e-01, -2.1161e-02,\n           -4.1636e-01, -1.2912e+00,  9.5027e-01],\n          [ 1.6386e+00,  9.1130e-01, -2.9084e-02,  8.8033e-01,  1.3543e+00,\n           -1.4643e+00, -2.5046e-02,  6.2117e-01,  1.0609e+00,  6.6845e-01,\n            1.5821e-01, -1.0598e+00, -3.3876e+00, -1.1218e+00, -1.4019e+00,\n            2.4498e+00, -7.1469e-01, -1.2732e+00, -1.6108e-01, -1.8009e-01,\n           -4.4487e-01,  4.8994e-01, -7.7627e-01, -1.9196e+00,  1.4769e+00,\n           -5.7532e-01,  1.4515e-01,  2.4947e-01],\n          [-9.3452e-01, -1.4012e+00, -6.3710e-01, -1.1447e+00,  7.1016e-01,\n            1.5342e+00,  1.4210e+00,  2.0957e+00,  5.6102e-01,  2.5351e-01,\n           -6.1829e-01, -9.8880e-01,  6.0835e-01, -1.6596e-01, -2.4013e-01,\n           -2.3057e-01, -1.0792e+00,  4.8203e-01, -4.2513e-01, -1.1715e+00,\n            5.4854e-01,  7.9151e-01,  6.4677e-01,  9.7515e-01,  4.1157e-01,\n            7.2924e-01,  6.7465e-02, -1.3425e+00]]]]), None"
     ]
    }
   ],
   "source": [
    "\n",
    "import onnxruntime as ort\n",
    " \n",
    "# 加载 ONNX 模型\n",
    "ort_session = ort.InferenceSession(\"lenet2.onnx\")\n",
    " \n",
    "# 准备输入信息\n",
    "input_info = ort_session.get_inputs()[0]\n",
    "input_name = input_info.name\n",
    "input_shape = input_info.shape\n",
    "input_type = input_info.type\n",
    " \n",
    " \n",
    "# 运行ONNX模型\n",
    "outputs = ort_session.run(input_name, dummy_input)\n",
    " \n",
    "# 获取输出信息\n",
    "output_info = ort_session.get_outputs()[0]\n",
    "output_name = output_info.name\n",
    "output_shape = output_info.shape\n",
    "output_data = outputs[0]\n",
    " \n",
    "print(\"outputs:\", outputs)\n",
    "print(\"output_info :\", output_info )\n",
    "print(\"output_name :\", output_name )\n",
    "print(\"output_shape :\", output_shape )\n",
    "print(\"output_data :\", output_data )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc74a8f",
   "metadata": {},
   "source": [
    "## 处理输入图片："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ffc3cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原图形状： (500, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=cv2.imread('../data/number/10.png',0)\n",
    "print(\"原图形状：\",img.shape) \n",
    "ret,img_bi=cv2.threshold(img,90,255,cv2.THRESH_BINARY)\n",
    "img_bi=255-img_bi\n",
    "cv2.imwrite('../data/number/img_ori_11.png',img_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b58d0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7205e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ls=[]\n",
    "y_ls=[]\n",
    "img_shape=img_bi.shape\n",
    "for i in range(img_shape[0]):\n",
    "    for j in range(img_shape[1]):\n",
    "        if img_bi[i,j] != 0:\n",
    "            x_ls.append(i)\n",
    "            y_ls.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d2460f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min =min(x_ls)\n",
    "x_max = max(x_ls)\n",
    "y_min =min(y_ls)\n",
    "y_max = max(y_ls)\n",
    "x_d = int((x_max-x_min)/5)\n",
    "y_d = int((y_max-y_min)/5)\n",
    "d=max(x_d,y_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ab1496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlen=x_max-x_min\n",
    "ylen=y_max-y_min\n",
    "max_len=max(xlen,ylen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b073a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=max_len+d\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5008ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_middle=int((x_max+x_min)/2)\n",
    "y_middle=int((y_max+y_min)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "71682502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74692177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "二值剪切之后形状： (438, 386)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img_bi=img_bi[x_min-x_d:x_max+x_d, y_min-y_d:y_max+y_d]\n",
    "# print(\"二值剪切之后形状：\",img_bi.shape)\n",
    "# cv2.imwrite('./data/number/img_binary_0.png',img_bi)\n",
    "\n",
    "img_bi=img_bi[max(0,x_middle-int(max_len/2)):min(x_middle+int(max_len/2),img.shape[0]), max(0,y_middle-int(max_len/2)):min(y_middle+int(max_len/2),img.shape[0])]\n",
    "print(\"二值剪切之后形状：\",img_bi.shape)\n",
    "cv2.imwrite('../data/number/10_ori.png',img_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "331cb617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "二值剪切变小之后形状： (28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#img_bi=cv2.resize(img_bi,(28,28),interpolation=cv2.INTER_AREA)\n",
    "img_bi=cv2.resize(img_bi,(28,28))\n",
    "print(\"二值剪切变小之后形状：\",img_bi.shape)\n",
    "cv2.imwrite('../data/number/10_oritrans.png',img_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ef0dfb12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trans=transforms.ToTensor()\n",
    "img_beingrate=trans(img_bi)\n",
    "img_beingrate=img_beingrate.view(1,1,28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a5b5d6",
   "metadata": {},
   "source": [
    "## 调用模型进行识别："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "609ce81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input=img_beingrate\n",
    "output=le(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4836c4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5943077e-07, 3.8181454e-01, 2.1393660e-03, 9.2032151e-06,\n",
       "        7.6142183e-05, 4.8497744e-04, 4.3295436e-03, 4.1186082e-05,\n",
       "        6.1108494e-01, 2.0063517e-05]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5da27ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=output.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "368da7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5943077e-07, 3.8181454e-01, 2.1393660e-03, 9.2032151e-06,\n",
       "        7.6142183e-05, 4.8497744e-04, 4.3295436e-03, 4.1186082e-05,\n",
       "        6.1108494e-01, 2.0063517e-05]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e4d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b388b78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8f64af5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#output_softmax = output_softmax.detach().cpu().numpy()\n",
    "# # 因为结果输出是二维 取第一行也就是一批量中的第一个  现在输入的一批就是一张\n",
    "pred = np.argmax(output)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9de4e24c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_softmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-e5511e017d2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_softmax\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_softmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'output_softmax' is not defined"
     ]
    }
   ],
   "source": [
    "prob=[]\n",
    "for i in range(10):\n",
    "    prob.append(round(output_softmax[i]/sum(output_softmax),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
